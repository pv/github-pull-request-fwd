#!/usr/bin/python
"""
github-pull-request-rss rss CACHE.json USER/PROJECT > out.rss
       github-pull-request-rss mbox CACHE.json USER/PROJECT > out.mbox
       github-pull-request-rss mail CACHE.json USER/PROJECT RECEIVER@SOMEWHERE


Generate an RSS feed from Github Pull Requests and all comments in
them.

What mails are generated is determined by the ``last_mailed`` timestamp
in CACHE.json, which you can adjust with the ``--catchup-mails`` option.

"""
import os
import sys
import re
import datetime
import urllib2
import json
import cgi
import optparse
import time
import random
import hashlib
import email
import jinja2
import smtplib
import errno

import locale
locale.setlocale(locale.LC_ALL, 'C')

API_URL_BASE = "http://github.com/api/v2/json/"
URL_BASE = "http://github.com/%s/%s/"

MAIL_TEMPLATE = u"""\
Message-ID: <{{message.unique_id}}@github-pull-request>
From: {{message.user}} (PR) <noreply@localhost>
{% if parent -%}
In-Reply-To: <{{parent.unique_id}}@github-pull-request>
References: <{{parent.unique_id}}@github-pull-request>
Subject: Re: [PR #{{message.number}}]: {{message.title}}
{%- else -%}
Subject: [PR #{{message.number}}]: {{message.title}}
{%- endif %}

{% for c in comments -%}
{%- if c.link and c.link != message.request_url -%}
{{ c.link }}

{% endif -%}
{% if not parent -%}{{message.title}}

{% endif -%}
{{ c.body }}
{%- if not loop.last %}

    ***

{% endif %}
{%- endfor %}

-- 
PR #{{ message.number }}: {{ message.request_url }}
(Please comment on Github rather than replying to this mail.)
"""

def main():
    p = optparse.OptionParser(usage=__doc__.strip())
    p.add_option("-p", "--pr-only", action="store_true", dest="pr_only",
                 help="produce feed containing only the pull requests")
    p.add_option("-c", "--max-count", action="store", type="int",
                 dest="max_count", default=100, metavar="COUNT",
                 help="maximum number of feed items (default: 100)")
    p.add_option("-n", "--no-update", action="store_true", dest="no_update",
                 help="don't download updated data from the internet")
    p.add_option("-t", "--ttl", action="store", type="int",
                 dest="ttl", default=360,
                 help="time-to-live in minutes (default: 360)")
    p.add_option("--smtp-server", action="store", metavar="HOST",
                 dest="smtp_server", default="localhost",
                 help="send mail via given SMTP server, instead of localhost")
    p.add_option("--catchup-mail", action="store",
                 dest="catchup", default=None, metavar="DATE",
                 help="consider only mails after DATE")
    p.add_option("--mail-template", action="store", metavar="FILE",
                 dest="mail_template", default=None,
                 help="template file for mails")
    p.add_option("--print-template", action="store_true",
                 dest="print_template", default=False,
                 help="print the default mail template")
    options, args = p.parse_args()

    if options.print_template:
        print MAIL_TEMPLATE
        return 0

    try:
        mode = args[0]
        cache_file = args[1]
        user, project = args[2].split('/')
        if mode == "mail":
            receiver = args[3]
        else:
            receiver = None
    except ValueError:
        p.error("Invalid arguments")

    if mode not in ["rss", "mail", "mbox"]:
        p.error("Invalid mode %r" % mode)

    if options.mail_template is None:
        mail_template = jinja2.Template(MAIL_TEMPLATE)
    else:
        with open(options.mail_template, "r") as f:
            mail_template = jinja2.Template(f.read())

    with LockFile(cache_file + ".lock"):
        data = GithubPulls(user, project, cache_file)

        if not options.no_update:
            data.update()
            data.save_cache()

        base_url = URL_BASE % (user, project)
        link = base_url + "pulls"

        if options.pr_only:
            title = "%s pull requests" % project
        else:
            title = "%s pull request chatter" % project

        if options.catchup is not None:
            if options.catchup in ("now", "all"):
                data.last_mailed = datetime.datetime.utcnow()
            else:
                data.last_mailed = parse_time(options.catchup)

        if mode in ("mail", "mbox"):
            mails = comments_to_mails(base_url, data.comments,
                                      last_mailed=data.last_mailed,
                                      pr_only=options.pr_only)
            try:
                send_mails(mails,
                           receiver=receiver,
                           template=mail_template,
                           server=options.smtp_server,
                           data=data,
                           output_mbox=(mode != "mail"))
            finally:
                data.save_cache()
        elif mode == "rss":
            posts = comments_to_posts(base_url, data.comments,
                                      pr_only=options.pr_only)
            rss = format_rss(posts[-options.max_count:], title=title, link=link,
                             ttl=options.ttl)
            sys.stdout.write(rss.encode('utf-8'))
        else:
            p.error("Unknown mode %r" % mode)

    return 0

def parse_time(s):
    """Parse a time string and convert to UTC"""

    # US time format
    m = re.match(r'^([0-9]+)/([0-9]+)/([0-9]+)\s*([0-9]+:[0-9]+:[0-9]+)\s*([+-][0-9][0-9][0-9][0-9])\s*$', s)
    if m:
        s = "%s-%s-%sT%s%s:%s" % (m.group(1), m.group(2), m.group(3),
                                  m.group(4), m.group(5)[:-2], m.group(5)[-2:])

    # UTC time format
    if s.endswith('Z'):
        return datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')

    # TZ time format
    m = re.search(r'([+-])([0-9]+):([0-9]+)$', s)
    if m:
        t = datetime.datetime.strptime(s[:m.start()], '%Y-%m-%dT%H:%M:%S')
        dt = datetime.timedelta(hours=int(m.group(2)),
                                minutes=int(m.group(3)))
        if m.group(1) == '+':
            t -= dt
        else:
            t += dt
        return t

    # Fallbacks
    fmts = ["%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
            "%Y-%m",
            "%Y"]
    for fmt in fmts:
        try:
            return datetime.datetime.strptime(s, fmt)
        except ValueError:
            continue

    # Unknown
    raise ValueError("Failed to parse date %r" % s)

class Comment(object):
    """
    Comment (or commit) from an user in the pull request discussion

    Attributes
    ----------
    user : str
        Name of the user
    body : str
        Body text written by the user, or the commit message
    timestamp : datetime.datetime
        Time stamp for posting this comment
    link : str
        URL relevant for this comment
    commit : str
        Git commit relevant for this comment
    request_number : int
        Pull request number
    request_title : str
        Pull request title
    """

    def __init__(self, user, body, timestamp, link=None, commit=None,
                 request_number=None, request_title=None):
        self.user = user
        self.body = body
        self.commit = commit
        self.link = link
        self.timestamp = timestamp
        self.request_number = int(request_number)
        self.request_title = request_title

    def __repr__(self):
        if self.commit:
            return "<Comment %s @ %-3d '%s': '%s' (%s)>" % (
                self.timestamp.strftime('%Y-%m-%d'),
                self.request_number,
                self.user,
                re.sub(r'[^a-zA-Z0-9: _.*-]', ' ', self.body[:20]),
                self.commit[:6]
                )
        else:
            return "<Comment %s @ %-3d '%s': '%s'>" % (
                self.timestamp.strftime('%Y-%m-%d'),
                self.request_number,
                self.user,
                re.sub(r'[^a-zA-Z0-9: _.*-]', ' ', self.body[:20]),
                )

class GithubPulls(object):
    """
    Fetch and cache Github pull request data.

    Saves most of the data in a cache file, so that the discussion
    threads do not need to be fetched except when changed.

    Attributes
    ----------
    comments : list of Comment
        Comments made in the pull request, sorted in ascending order
        by post timestamp

    """

    def __init__(self, user, project, cachefile):
        self._requests = {}
        self.last_mailed = datetime.datetime(1970, 1, 1)
        self._cachefile = cachefile
        self.user = user
        self.project = project

        if os.path.isfile(cachefile):
            self.load_cache()

    def load_cache(self):
        """Load data from cache file"""
        with open(self._cachefile, 'rb') as f:
            d = json.load(f)
            self._requests = {}
            for k, v in d['requests'].items():
                self._requests[int(k)] = v
            self.last_mailed = datetime.datetime(1970, 1, 1)
            if 'last_mailed' in d:
                self.last_mailed = datetime.datetime.strptime(
                    d['last_mailed'], '%Y-%m-%dT%H:%M:%SZ')

    def save_cache(self):
        """Save data to cache file"""
        tmp_file = self._cachefile + '.new'
        last_mailed_str = self.last_mailed.strftime('%Y-%m-%dT%H:%M:%SZ')
        with open(tmp_file, 'wb') as f:
            json.dump(dict(requests=self._requests,
                           last_mailed=last_mailed_str), f)
        # atomic replace
        os.rename(tmp_file, self._cachefile)

    def update(self):
        """Update local state by fetching data from github.com"""
        url = API_URL_BASE + "pulls/%s/%s/open" % (self.user, self.project)
        print >> sys.stderr, "Fetch:", url
        f = urllib2.urlopen(url)
        try:
            open_data = json.load(f)
        finally:
            f.close()

        url = API_URL_BASE + "pulls/%s/%s/closed" % (self.user, self.project)
        print >> sys.stderr, "Fetch:", url
        f = urllib2.urlopen(url)
        try:
            closed_data = json.load(f)
        finally:
            f.close()

        data = open_data
        data['pulls'].extend(closed_data['pulls'])
        self._update_from_data(data)

    def _update_from_data(self, data):
        # Check which pull requests need updating
        new_list = {}
        need_update = set()
        for request in data['pulls']:
            old_request = self._requests.get(request['number'])

            if old_request is None:
                need_update.add(request['number'])
            else:
                t_new = parse_time(request['updated_at'])
                t_old = parse_time(old_request['updated_at'])
                if t_new != t_old:
                    need_update.add(request['number'])

            new_list[request['number']] = request

        # Fetch updated data, when needed
        for number, request in new_list.items():
            if number not in need_update:
                req = dict(self._requests[number])
                req.update(request)
                request.update(req)
            else:
                self._fetch_request(number, request)

        # Done
        self._requests = new_list

    def _fetch_request(self, number, request):
        url = API_URL_BASE + "pulls/%s/%s/%d" % (self.user, self.project,
                                                 number)
        print >> sys.stderr, "Fetch:", url
        last_err = None
        for trial in range(3):
            try:
                time.sleep(random.random())
                f = urllib2.urlopen(url)
                break
            except urllib2.HTTPError, err:
                last_err = err
                w = 1 + 10*trial**2
                print >> sys.stderr, "Fail: %s, retry in %d sec" % (err, w)
                time.sleep(w)
        else:
            raise RuntimeError("Fetching request failed: %s" % last_err)

        try:
            data = json.load(f)
        finally:
            f.close()
        request.update(data['pull'])

    @property
    def comments(self):
        items = []

        def get_user(item):
            if not item['user']:
                return "(No user)"
            return item['user'].get('name') or item['user']['login']

        for request in self._requests.values():
            item = Comment(user=get_user(request),
                           body=request['body'],
                           link=request['html_url'],
                           timestamp=parse_time(request['created_at']),
                           request_number=request['number'],
                           request_title=request['title'],
                           )
            items.append(item)

            request_timestamp_delta = (item.timestamp
                                       + datetime.timedelta(microseconds=1))

            for j, entry in enumerate(request.get('discussion', [])):
                request_timestamp_delta += datetime.timedelta(microseconds=1)
                if entry['type'].lower() == 'commit':
                    repo = request['head']['repository']
                    if repo is None:
                        repo = request['base']['repository']
                    link = u"%s/commit/%s" % (
                        repo['url'],
                        entry['id'])
                    item = Comment(user=get_user(entry),
                                   body=entry['message'],
                                   timestamp=max(request_timestamp_delta,
                                                 parse_time(entry['committed_date'])),
                                   commit=entry['id'],
                                   link=link,
                                   request_number=request['number'],
                                   request_title=request['title'],
                                   )
                    items.append(item)
                elif entry['type'].lower() == 'issuecomment':
                    item = Comment(user=get_user(entry),
                                   body=entry['body'],
                                   timestamp=max(request_timestamp_delta,
                                                 parse_time(entry['created_at'])),
                                   request_number=request['number'],
                                   request_title=request['title'],
                                   )
                    items.append(item)
                elif entry['type'].lower() in ('pullrequestreviewcomment',
                                               'commitcomment'):
                    repo = request['head']['repository']
                    if repo is None:
                        repo = request['base']['repository']
                    if 'position' in entry:
                        link = u"%s/commit/%s#%s-P%s" % (
                            repo['url'],
                            entry['commit_id'],
                            entry['path'],
                            entry['position'])
                    else:
                        link = u"%s/commit/%s#%s" % (
                            repo['url'],
                            entry['commit_id'],
                            entry['path'])
                    item = Comment(user=get_user(entry),
                                   body=entry['body'],
                                   timestamp=max(request_timestamp_delta,
                                                 parse_time(entry['created_at'])),
                                   request_number=request['number'],
                                   request_title=request['title'],
                                   link=link,
                                   )
                    items.append(item)
                else:
                    raise ValueError("Unknown item type %r" % entry['type'])

        items.sort(key=lambda x: x.timestamp)

        return items


#------------------------------------------------------------------------------
# RSS formatting
#------------------------------------------------------------------------------

class RssPost(object):
    """
    RSS post entry

    Attributes
    ----------
    timestamp : datetime.datetime
        Post timestamp
    html : str
        Post content
    title : str
        Post title
    link : str
        Link corresponding to post title

    """

    def __init__(self, timestamp, html, title, link):
        self.timestamp = timestamp
        self.html = html
        self.title = title
        self.link = link

    @property
    def guid(self):
        return "%016x" % hash((self.timestamp, self.html,
                               self.title, self.link))

    def __repr__(self):
        return "<RssPost %s: %s>" % (
            self.timestamp.strftime('%Y-%m-%d'),
            re.sub(r'[^a-zA-Z0-9: _.#*-]', ' ', self.title[:20]))

def comments_to_posts(base_uri, comments, pr_only=False):
    """
    Convert comments to a series of RSS posts.

    Bunch comments related to the same pull request together, if they
    have been posted not too long ago from each other.

    """

    posts = []
    bunch = []

    seen_requests = {}

    def process_bunch():
        if not bunch:
            return

        c0 = bunch[0]

        timestamp = max(c.timestamp for c in bunch)
        request_number = c0.request_number
        request_title = c0.request_title
        title = "#%d (%s): %s..." % (request_number,
                                     cgi.escape(request_title[:50]),
                                     cgi.escape(c0.body[:20]))
        title_link = base_uri + ("pull/%d" % request_number)
        html = []

        for c in bunch:
            text = u"<pre>%s</pre>" % cgi.escape(c.body.replace("\r", ""))
            date_text = u"%s -- %s" % (
                c.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                cgi.escape(c.user))
            if c.commit:
                date_text = "%s <a href=\"%s\">[commit %s]</a>" % (
                    date_text, cgi.escape(c.link, quote=True), c.commit[:6])
            elif c.link:
                date_text = "%s <a href=\"%s\">[link]</a>" % (
                    date_text, cgi.escape(c.link, quote=True))

            html.append(u"<p><b>%s</b></p><p>%s</p>" % (date_text, text))
        html = "<hr/>".join(html)

        if request_number not in seen_requests or not pr_only:
            posts.append(RssPost(timestamp=timestamp,
                                 html=html,
                                 link=title_link,
                                 title=title))
            seen_requests[request_number] = True

        del bunch[:]

    last_date = None
    last_number = None
    bunch_treshold = datetime.timedelta(hours=1)

    for c in comments:
        unbunch = False

        if last_number != c.request_number:
            unbunch = True
        if last_date and (c.timestamp - last_date) > bunch_treshold:
            unbunch = True

        if unbunch:
            process_bunch()
            bunch.append(c)
            last_date = c.timestamp
            last_number = c.request_number
        else:
            bunch.append(c)
            last_date = c.timestamp

    process_bunch()

    return posts


def format_rss(posts, title=u"", description=u"", link=u"", ttl=1800):
    """
    Convert a list of RSS post to a string containing RSS xml.

    """

    timefmt = '%a, %0d %b %Y %H:%M:%S +0000'

    items = []
    for post in reversed(posts):
        params = dict(title=post.title,
                      link=post.link,
                      body=cgi.escape(post.html.replace("\n", "<br/>")),
                      guid=post.guid,
                      date=post.timestamp.strftime(timefmt))

        items.append(u"""\
<title>%(title)s</title>
  <description>%(body)s</description>
  <link>%(link)s</link>
  <guid>%(guid)s</guid>
  <pubDate>%(date)s</pubDate>\
""" % params)

    params = dict(
        items=u"\n".join(u"<item>%s</item>" % x for x in items),
        link=link,
        title=title,
        description=description,
        ttl=ttl,
        build_date=datetime.datetime.utcnow().strftime(timefmt),
        pub_date=datetime.datetime.utcnow().strftime(timefmt),
        )

    rss = u"""\
<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
  <title>%(title)s</title>
  <description>%(description)s</description>
  <link>%(link)s</link>
  <lastBuildDate>%(build_date)s</lastBuildDate>
  <pubDate>%(pub_date)s</pubDate>
  <ttl>%(ttl)d</ttl>
%(items)s
</channel>
</rss>
""" % params

    return rss


#------------------------------------------------------------------------------
# Mail formatting
#------------------------------------------------------------------------------

class Mail(object):
    def __init__(self, user, timestamp, number, title, parent,
                 request_url, comments):
        self.user = user
        self.timestamp = timestamp
        self.title = title
        self.number = number
        self.parent = parent
        self.request_url = request_url
        self.comments = comments

    @property
    def unique_id(self):
        r = hashlib.md5()
        r.update(str(self.number))
        r.update(self.user.encode('utf-8'))
        r.update(self.timestamp.strftime("%Y-%m-%-dT%H:%M:%SZ"))
        return r.hexdigest()

    def format(self, template):
        return template.render(message=self, parent=self.parent,
                               comments=self.comments).encode('utf-8')

def comments_to_mails(base_uri, comments, last_mailed, pr_only=False):
    mails = []
    requests = {}

    bunch = []

    def process_bunch():
        if not bunch:
            return

        c = bunch[0]
        if c.request_number not in requests:
            parent = None
        else:
            parent = requests[c.request_number]
            if pr_only:
                del bunch[:]
                return

        request_url = base_uri + ("pull/%d" % c.request_number)

        m = Mail(user=c.user,
                 comments=list(bunch),
                 timestamp=c.timestamp,
                 number=c.request_number,
                 title=c.request_title,
                 parent=parent,
                 request_url=request_url)

        mails.append(m)

        if parent is None:
            requests[c.request_number] = m

        del bunch[:]

    last_number = None
    last_user = None

    for c in comments:
        if c.timestamp <= last_mailed:
            continue

        unbunch = False
        if last_number != c.request_number or last_user != c.user:
            unbunch = True

        if unbunch:
            process_bunch()
            bunch.append(c)
            last_number = c.request_number
            last_user = c.user
        else:
            bunch.append(c)

    process_bunch()

    return mails

def send_mails(mails, receiver, template, server, data, output_mbox=False):
    mails.sort(key=lambda x: x.timestamp)

    if not output_mbox:
        smtp = smtplib.SMTP()
        smtp.connect(server)

    for j, mail in enumerate(mails):
        text = mail.format(template)
        msg = email.message_from_string(text)
        msg['Date'] = mail.timestamp.strftime("%a, %d %b %Y %H:%M:%S +000")

        assert 'From' in msg and 'Subject' in msg

        sender_name, sender_email = email.utils.parseaddr(msg['From'])
        print >> sys.stderr, "Sending mail (%d/%d): %s" % (
            j, len(mails), msg['Subject'][:40])

        if output_mbox:
            print msg
            print ""
        else:
            smtp.sendmail(sender_email, [receiver], msg.as_string())

        data.last_mailed = mail.timestamp

        if (j+1) % 200 == 0 and not output_mbox:
            # reconnect
            smtp.close()
            smtp = smtplib.SMTP()
            smtp.connect(server)


#------------------------------------------------------------------------------
# Lock file
#------------------------------------------------------------------------------

class LockFile(object):
    """
    Lock file (Unix-only).
    """

    def __init__(self, filename):
        self.filename = filename
        self.fd = None

    def __enter__(self):
        for tries in range(3):
            if tries > 0:
                print >> sys.stderr, "Another process running -- waiting..."
                time.sleep(1 + tries**2)

            try:
                os.symlink(str(os.getpid()), self.filename)
                break
            except OSError, err:
                if err.errno != errno.EEXIST:
                    raise

                try:
                    pid = int(os.readlink(self.filename))
                except OSError, err:
                    if err.errno == errno.ENOENT:
                        continue
                    raise

                # Check if it's still alive
                try:
                    os.kill(pid, 0)
                except OSError, err:
                    if err.errno == errno.ESRCH:
                        # no such process
                        os.unlink(self.filename)
                        continue
                    raise
        else:
            raise RuntimeError("Another process running -- timed out.")

    def __exit__(self, type, value, traceback):
        os.unlink(self.filename)


#------------------------------------------------------------------------------

if __name__ == "__main__":
    sys.exit(main())
