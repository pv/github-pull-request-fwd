#!/usr/bin/python
"""
github-pull-request-rss CACHE.json USER/PROJECT > out.rss

Generate an RSS feed from Github Pull Requests and all comments in
them.

"""
import os
import sys
import re
import datetime
import urllib2
import json
import cgi
import optparse

import locale
locale.setlocale(locale.LC_ALL, 'C')

API_URL_BASE = "http://github.com/api/v2/json/"
URL_BASE = "http://github.com/%s/%s/"

def main():
    p = optparse.OptionParser(usage=__doc__.strip())
    p.add_option("-p", "--pr-only", action="store_true", dest="pr_only",
                 help="produce feed containing only the pull requests")
    p.add_option("-m", "--max-count", action="store", type="int",
                 dest="max_count", default=100,
                 help="maximum number of feed items (default: 100)")
    p.add_option("-n", "--no-update", action="store_true", dest="no_update",
                 help="don't download updated data from the internet")
    options, args = p.parse_args()

    if len(args) != 2:
        p.error("Invalid number of arguments")

    try:
        cache_file = args[0]
        user, project = args[1].split('/')
    except ValueError:
        p.error("Invalid arguments")

    data = GithubPulls(user, project, cache_file)

    if not options.no_update:
        data.update()
        data.save_cache()

    base_url = URL_BASE % (user, project)
    link = base_url + "pulls"

    if options.pr_only:
        title = "%s pull requests" % project
    else:
        title = "%s pull request chatter" % project

    posts = comments_to_posts(base_url, data.comments, pr_only=options.pr_only)
    rss = format_rss(posts[-options.max_count:], title=title, link=link)
    sys.stdout.write(rss.encode('utf-8'))

    return 0

def parse_time(s):
    """Parse a time string and convert to UTC"""

    # US time format
    m = re.match(r'^([0-9]+)/([0-9]+)/([0-9]+)\s*([0-9]+:[0-9]+:[0-9]+)\s*([+-][0-9][0-9][0-9][0-9])\s*$', s)
    if m:
        s = "%s-%s-%sT%s%s:%s" % (m.group(1), m.group(2), m.group(3),
                                  m.group(4), m.group(5)[:-2], m.group(5)[-2:])

    # UTC time format
    if s.endswith('Z'):
        return datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')

    # TZ time format
    m = re.search(r'([+-])([0-9]+):([0-9]+)$', s)
    if m:
        t = datetime.datetime.strptime(s[:m.start()], '%Y-%m-%dT%H:%M:%S')
        dt = datetime.timedelta(hours=int(m.group(2)),
                                minutes=int(m.group(3)))
        if m.group(1) == '+':
            t -= dt
        else:
            t += dt
        return t

    # Unknown
    raise ValueError("Failed to parse date %r" % s)

class attrdict(dict):
    __getattr__ = dict.__getitem__
    __setattr__ = dict.__setitem__

class Comment(object):
    def __init__(self, user, body, timestamp, link=None, commit=None,
                 request_number=None, request_title=None):
        self.user = user
        self.body = body
        self.commit = commit
        self.link = link
        self.timestamp = timestamp
        self.request_number = int(request_number)
        self.request_title = request_title

    def __repr__(self):
        if self.commit:
            return "<Comment %s @ %-3d '%s': '%s' (%s)>" % (
                self.timestamp.strftime('%Y-%m-%d'),
                self.request_number,
                self.user,
                re.sub(r'[^a-zA-Z0-9: _.*-]', ' ', self.body[:20]),
                self.commit[:6]
                )
        else:
            return "<Comment %s @ %-3d '%s': '%s'>" % (
                self.timestamp.strftime('%Y-%m-%d'),
                self.request_number,
                self.user,
                re.sub(r'[^a-zA-Z0-9: _.*-]', ' ', self.body[:20]),
                )

class GithubPulls(object):
    """
    Fetch and cache Github pull request data
    """

    def __init__(self, user, project, cachefile):
        self._requests = {}
        self._cachefile = cachefile
        self.user = user
        self.project = project

        if os.path.isfile(cachefile):
            self.load_cache()

    def load_cache(self):
        """Load data from cache file"""
        with open(self._cachefile, 'rb') as f:
            d = json.load(f)
            self._requests = {}
            for k, v in d['requests'].items():
                self._requests[int(k)] = v

    def save_cache(self):
        """Save data to cache file"""
        tmp_file = self._cachefile + '.new'
        with open(tmp_file, 'wb') as f:
            json.dump(dict(requests=self._requests), f)
        # atomic replace
        os.rename(tmp_file, self._cachefile)

    def update(self):
        """Update local state by fetching data from github.com"""
        url = API_URL_BASE + "pulls/%s/%s/open" % (self.user, self.project)
        print >> sys.stderr, "Fetch:", url
        f = urllib2.urlopen(url)
        try:
            open_data = json.load(f)
        finally:
            f.close()

        url = API_URL_BASE + "pulls/%s/%s/closed" % (self.user, self.project)
        print >> sys.stderr, "Fetch:", url
        f = urllib2.urlopen(url)
        try:
            closed_data = json.load(f)
        finally:
            f.close()

        data = open_data
        data['pulls'].extend(closed_data['pulls'])
        self._update_from_data(data)

    def _update_from_data(self, data):
        # Check which pull requests need updating
        new_list = {}
        need_update = set()
        for request in data['pulls']:
            old_request = self._requests.get(request['number'])

            if old_request is None:
                need_update.add(request['number'])
            else:
                t_new = parse_time(request['updated_at'])
                t_old = parse_time(old_request['updated_at'])
                if t_new != t_old:
                    need_update.add(request['number'])

            new_list[request['number']] = request

        # Fetch updated data, when needed
        for number, request in new_list.items():
            if number not in need_update:
                req = dict(self._requests[number])
                req.update(request)
                request.update(req)
            else:
                self._fetch_request(number, request)

        # Done
        self._requests = new_list

    def _fetch_request(self, number, request):
        url = API_URL_BASE + "pulls/%s/%s/%d" % (self.user, self.project,
                                                 number)
        print >> sys.stderr, "Fetch:", url
        f = urllib2.urlopen(url)
        try:
            data = json.load(f)
        finally:
            f.close()
        request.update(data['pull'])

    @property
    def comments(self):
        items = []

        def get_user(item):
            if not item['user']:
                return "Nobody"
            return item['user'].get('name') or item['user']['login']

        for request in self._requests.values():
            item = Comment(user=get_user(request),
                           body=request['body'],
                           link=request['html_url'],
                           timestamp=parse_time(request['created_at']),
                           request_number=request['number'],
                           request_title=request['title'],
                           )
            items.append(item)

            request_timestamp_delta = (item.timestamp
                                       + datetime.timedelta(microseconds=1))

            for j, entry in enumerate(request.get('discussion', [])):
                request_timestamp_delta += datetime.timedelta(microseconds=1)
                if entry['type'].lower() == 'commit':
                    repo = request['head']['repository']
                    if repo is None:
                        repo = request['base']['repository']
                    link = u"%s/commit/%s" % (
                        repo['url'],
                        entry['id'])
                    item = Comment(user=get_user(entry),
                                   body=entry['message'],
                                   timestamp=max(request_timestamp_delta,
                                                 parse_time(entry['committed_date'])),
                                   commit=entry['id'],
                                   link=link,
                                   request_number=request['number'],
                                   request_title=request['title'],
                                   )
                    items.append(item)
                elif entry['type'].lower() == 'issuecomment':
                    item = Comment(user=get_user(entry),
                                   body=entry['body'],
                                   timestamp=max(request_timestamp_delta,
                                                 parse_time(entry['created_at'])),
                                   request_number=request['number'],
                                   request_title=request['title'],
                                   )
                    items.append(item)
                elif entry['type'].lower() in ('pullrequestreviewcomment',
                                               'commitcomment'):
                    repo = request['head']['repository']
                    if repo is None:
                        repo = request['base']['repository']
                    if 'position' in entry:
                        link = u"%s/commit/%s#%s-P%s" % (
                            repo['url'],
                            entry['commit_id'],
                            entry['path'],
                            entry['position'])
                    else:
                        link = u"%s/commit/%s#%s" % (
                            repo['url'],
                            entry['commit_id'],
                            entry['path'])
                    item = Comment(user=get_user(entry),
                                   body=entry['body'],
                                   timestamp=max(request_timestamp_delta,
                                                 parse_time(entry['created_at'])),
                                   request_number=request['number'],
                                   request_title=request['title'],
                                   link=link,
                                   )
                    items.append(item)
                else:
                    raise ValueError("Unknown item type %r" % entry['type'])

        items.sort(key=lambda x: x.timestamp)

        return items

class RssPost(object):
    def __init__(self, timestamp, html, title, link):
        self.timestamp = timestamp
        self.html = html
        self.title = title
        self.link = link

    @property
    def guid(self):
        return "%016x" % hash((self.timestamp, self.title))

    def __repr__(self):
        return "<RssPost %s: %s>" % (
            self.timestamp.strftime('%Y-%m-%d'),
            re.sub(r'[^a-zA-Z0-9: _.#*-]', ' ', self.title[:20]))

def comments_to_posts(base_uri, comments, pr_only=False):
    posts = []
    bunch = []

    seen_requests = {}

    def process_bunch():
        if not bunch:
            return

        c0 = bunch[0]

        timestamp = max(c.timestamp for c in bunch)
        request_number = c0.request_number
        request_title = c0.request_title
        title = "#%d (%s): %s..." % (request_number,
                                     cgi.escape(request_title[:50]),
                                     cgi.escape(c0.body[:20]))
        title_link = base_uri + ("pull/%d" % request_number)
        html = []

        for c in bunch:
            text = u"<pre>%s</pre>" % cgi.escape(c.body.replace("\r", ""))
            date_text = u"%s -- %s" % (
                c.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                cgi.escape(c.user))
            if c.commit:
                date_text = "%s <a href=\"%s\">[commit %s]</a>" % (
                    date_text, cgi.escape(c.link, quote=True), c.commit[:6])
            elif c.link:
                date_text = "%s <a href=\"%s\">[link]</a>" % (
                    date_text, cgi.escape(c.link, quote=True))

            html.append(u"<p><b>%s</b></p><p>%s</p>" % (date_text, text))
        html = "<hr/>".join(html)

        if request_number not in seen_requests or not pr_only:
            posts.append(RssPost(timestamp=timestamp,
                                 html=html,
                                 link=title_link,
                                 title=title))
            seen_requests[request_number] = True

        del bunch[:]

    last_date = None
    last_number = None
    bunch_treshold = datetime.timedelta(hours=1)

    for c in comments:
        unbunch = False

        if last_number != c.request_number:
            unbunch = True
        if last_date and (c.timestamp - last_date) > bunch_treshold:
            unbunch = True

        if unbunch:
            process_bunch()
            bunch.append(c)
            last_date = c.timestamp
            last_number = c.request_number
        else:
            bunch.append(c)
            last_date = c.timestamp

    process_bunch()

    return posts

def format_rss(posts, title=u"", description=u"", link=u"", ttl=1800):
    timefmt = '%a, %0d %b %Y %H:%M:%S +0000'

    items = []
    for post in reversed(posts):
        params = dict(title=post.title,
                      link=post.link,
                      body=cgi.escape(post.html.replace("\n", "<br/>")),
                      guid=post.guid,
                      date=post.timestamp.strftime(timefmt))

        items.append(u"""\
<title>%(title)s</title>
  <description>%(body)s</description>
  <link>%(link)s</link>
  <guid>%(guid)s</guid>
  <pubDate>%(date)s</pubDate>\
""" % params)

    params = dict(
        items=u"\n".join(u"<item>%s</item>" % x for x in items),
        link=link,
        title=title,
        description=description,
        ttl=ttl,
        build_date=datetime.datetime.utcnow().strftime(timefmt),
        pub_date=datetime.datetime.utcnow().strftime(timefmt),
        )

    rss = u"""\
<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
  <title>%(title)s</title>
  <description>%(description)s</description>
  <link>%(link)s</link>
  <lastBuildDate>%(build_date)s</lastBuildDate>
  <pubDate>%(pub_date)s</pubDate>
  <ttl>%(ttl)d</ttl>
%(items)s
</channel>
</rss>
""" % params

    return rss

if __name__ == "__main__":
    sys.exit(main())
